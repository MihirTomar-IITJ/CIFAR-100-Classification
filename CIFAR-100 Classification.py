# -*- coding: utf-8 -*-
"""M24AIR006.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k5sLmEJ1K1xEKDHkgrJXBFyoVDK1ePlw
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
from torch.utils.data import DataLoader, random_split
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score
from torch.utils.data import WeightedRandomSampler

# ===========================
# 1. Dataset & Transformations
# ===========================
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ResNet requires 224x224 input
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Standard ImageNet normalization
])

# Load CIFAR-100 dataset
train_dataset = datasets.CIFAR100(root="./data", train=True, transform=transform, download=True)
test_dataset = datasets.CIFAR100(root="./data", train=False, transform=transform, download=True)

# CIFAR-100 Class to Superclass Mapping (for 100 classes)
CLASS_TO_SUPERCLASS = {
    0: "aquatic mammals", 1: "aquatic mammals", 2: "aquatic mammals", 3: "aquatic mammals", 4: "aquatic mammals",  # 0-4
    5: "fish", 6: "fish", 7: "fish", 8: "fish", 9: "fish",  # 5-9
    10: "flowers", 11: "flowers", 12: "flowers", 13: "flowers", 14: "flowers",  # 10-14
    15: "food containers", 16: "food containers", 17: "food containers", 18: "food containers", 19: "food containers",  # 15-19
    20: "fruits and vegetables", 21: "fruits and vegetables", 22: "fruits and vegetables", 23: "fruits and vegetables", 24: "fruits and vegetables",  # 20-24
    25: "household electrical devices", 26: "household electrical devices", 27: "household electrical devices", 28: "household electrical devices", 29: "household electrical devices",  # 25-29
    30: "household furniture", 31: "household furniture", 32: "household furniture", 33: "household furniture", 34: "household furniture",  # 30-34
    35: "insects", 36: "insects", 37: "insects", 38: "insects", 39: "insects",  # 35-39
    40: "large carnivores", 41: "large carnivores", 42: "large carnivores", 43: "large carnivores", 44: "large carnivores",  # 40-44
    45: "large man-made outdoor things", 46: "large man-made outdoor things", 47: "large man-made outdoor things", 48: "large man-made outdoor things", 49: "large man-made outdoor things",  # 45-49
    50: "large natural outdoor scenes", 51: "large natural outdoor scenes", 52: "large natural outdoor scenes", 53: "large natural outdoor scenes", 54: "large natural outdoor scenes",  # 50-54
    55: "large omnivores and herbivores", 56: "large omnivores and herbivores", 57: "large omnivores and herbivores", 58: "large omnivores and herbivores", 59: "large omnivores and herbivores",  # 55-59
    60: "medium-sized mammals", 61: "medium-sized mammals", 62: "medium-sized mammals", 63: "medium-sized mammals", 64: "medium-sized mammals",  # 60-64
    65: "non-insect invertebrates", 66: "non-insect invertebrates", 67: "non-insect invertebrates", 68: "non-insect invertebrates", 69: "non-insect invertebrates",  # 65-69
    70: "people", 71: "people", 72: "people", 73: "people", 74: "people",  # 70-74
    75: "reptiles", 76: "reptiles", 77: "reptiles", 78: "reptiles", 79: "reptiles",  # 75-79
    80: "small mammals", 81: "small mammals", 82: "small mammals", 83: "small mammals", 84: "small mammals",  # 80-84
    85: "trees", 86: "trees", 87: "trees", 88: "trees", 89: "trees",  # 85-89
    90: "vehicles1", 91: "vehicles1", 92: "vehicles1", 93: "vehicles1", 94: "vehicles1",  # 90-94
    95: "vehicles2", 96: "vehicles2", 97: "vehicles2", 98: "vehicles2", 99: "vehicles2"  # 95-99
}

# Mapping from Superclass to Group
SUPERCLASS_TO_GROUP = {
    "flowers": "Plants/Parts of plants",
    "trees": "Plants/Parts of plants",
    "fruits and vegetables": "Plants/Parts of plants",
    "vehicles1": "Vehicles",
    "vehicles2": "Vehicles",
    "non-insect invertebrates": "Invertebrates",
    "insects": "Invertebrates",
    "fish": "Aquatic animals",
    "aquatic mammals": "Aquatic animals",
    "large carnivores": "Large animals",
    "large omnivores and herbivores": "Large animals",
    "food containers": "Man-made articles",
    "household electrical devices": "Man-made articles",
    "household furniture": "Man-made articles",
    "large man-made outdoor things": "Man-made articles",
    "people": "People",
    "reptiles": "Normal Terrestrial Animals",
    "medium-sized mammals": "Normal Terrestrial Animals",
    "small mammals": "Normal Terrestrial Animals",
    "large natural outdoor scenes": "Outdoor scenes"
}

# Create mapping from superclass/group to index
SUPERCLASS_TO_IDX = {name: idx for idx, name in enumerate(set(CLASS_TO_SUPERCLASS.values()))}
GROUP_TO_IDX = {name: idx for idx, name in enumerate(set(SUPERCLASS_TO_GROUP.values()))}

def get_labels(targets):
    # Convert targets to a NumPy array for iteration
    targets = targets.cpu().numpy()
    # Map class indices to corresponding superclass and group indices
    superclass_labels = torch.tensor([SUPERCLASS_TO_IDX[CLASS_TO_SUPERCLASS[t]] for t in targets])
    group_labels = torch.tensor([GROUP_TO_IDX[SUPERCLASS_TO_GROUP[CLASS_TO_SUPERCLASS[t]]] for t in targets])
    return torch.tensor(targets), superclass_labels, group_labels

# Function to compute class weights for handling imbalance in a Subset (from random_split)
def get_balanced_sampler(dataset):
    # dataset.indices gives indices in the original dataset
    class_counts = np.bincount([dataset.dataset.targets[i] for i in dataset.indices])
    class_weights = 1.0 / class_counts
    sample_weights = [class_weights[dataset.dataset.targets[i]] for i in dataset.indices]
    return WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)

# ===========================
# 2. Data Splits (70:30, 80:20, 90:10)
# ===========================
splits = [0.7, 0.8, 0.9]  # Define the splits (percentage of training data)
batch_size = 256

# Dictionary to store data loaders for each split
data_loaders = {}
for split in splits:
    train_size = int(split * len(train_dataset))
    val_size = len(train_dataset) - train_size
    train_set, val_set = random_split(train_dataset, [train_size, val_size])

    # Apply oversampling ONLY to the training set using balanced sampler
    sampler = get_balanced_sampler(train_set)
    train_loader = DataLoader(train_set, batch_size=batch_size, sampler=sampler)

    # Validation and test loaders remain unchanged
    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    data_loaders[split] = (train_loader, val_loader, test_loader)

# ===========================
# 3. Define Multi-Task ResNet Model
# ===========================
class MultiTaskResNet(nn.Module):
    def __init__(self, base_model):
        super(MultiTaskResNet, self).__init__()
        self.resnet = base_model
        self.resnet.fc = nn.Identity()  # Remove the original FC layer
        # For ResNet18, feature dimension is 512; adjust if needed for other models.
        feature_dim = 512 if base_model.__class__.__name__ == 'ResNet' and base_model.layer1[0].conv1.in_channels == 64 else 2048

        # Define three classifier heads:
        self.classifier1 = nn.Linear(feature_dim, 100)  # 100 classes
        self.classifier2 = nn.Linear(feature_dim, len(SUPERCLASS_TO_IDX))  # Number of superclasses
        self.classifier3 = nn.Linear(feature_dim, len(GROUP_TO_IDX))  # Number of groups

    def forward(self, x):
        x = self.resnet(x)
        return self.classifier1(x), self.classifier2(x), self.classifier3(x)

    def count_parameters(self):
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        non_trainable_params = sum(p.numel() for p in self.parameters() if not p.requires_grad)
        return trainable_params, non_trainable_params

# ===========================
# 4. Model Training Function
# ===========================
def train(model, train_loader, optimizer, criterion, device="cuda"):
    model.train()
    total_loss = 0
    for images, targets in train_loader:
        images, targets = images.to(device), targets.to(device)
        labels1, labels2, labels3 = get_labels(targets)
        labels1, labels2, labels3 = labels1.to(device), labels2.to(device), labels3.to(device)

        optimizer.zero_grad()
        out1, out2, out3 = model(images)
        loss1 = criterion(out1, labels1)
        loss2 = criterion(out2, labels2)
        loss3 = criterion(out3, labels3)
        loss = loss1 + loss2 + loss3
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(train_loader)

# ===========================
# 5. Model Evaluation Function
# ===========================
def evaluate(model, val_loader, criterion, device="cuda"):
    model.eval()
    all_preds1, all_preds2, all_preds3 = [], [], []
    all_labels1, all_labels2, all_labels3 = [], [], []
    total_loss = 0

    with torch.no_grad():
        for images, targets in val_loader:
            images, targets = images.to(device), targets.to(device)
            labels1, labels2, labels3 = get_labels(targets)
            labels1, labels2, labels3 = labels1.to(device), labels2.to(device), labels3.to(device)
            out1, out2, out3 = model(images)
            loss1 = criterion(out1, labels1)
            loss2 = criterion(out2, labels2)
            loss3 = criterion(out3, labels3)
            total_loss += (loss1 + loss2 + loss3).item()
            all_preds1.extend(out1.argmax(1).cpu().numpy())
            all_preds2.extend(out2.argmax(1).cpu().numpy())
            all_preds3.extend(out3.argmax(1).cpu().numpy())
            all_labels1.extend(labels1.cpu().numpy())
            all_labels2.extend(labels2.cpu().numpy())
            all_labels3.extend(labels3.cpu().numpy())

    acc1 = accuracy_score(all_labels1, all_preds1)
    acc2 = accuracy_score(all_labels2, all_preds2)
    acc3 = accuracy_score(all_labels3, all_preds3)
    return total_loss / len(val_loader), acc1, acc2, acc3

# ===========================
# 6. Plot Confusion Matrix Function
# ===========================
def plot_confusion_matrix(y_true, y_pred, labels, title, figsize=(14, 12)):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=figsize)
    sns.heatmap(cm, annot=False, fmt="d", cmap="coolwarm", xticklabels=labels, yticklabels=labels)
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.title(title)
    plt.xticks(rotation=90, fontsize=8)
    plt.yticks(rotation=0, fontsize=8)
    plt.show()

# ===========================
# 7. Training Loop for Each Split with Confusion Matrix Output
# ===========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
base_model = models.resnet18(pretrained=True)
model = MultiTaskResNet(base_model).to(device)

optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# Loop over each split (70:30, 80:20, 90:10)
for split, (train_loader, val_loader, test_loader) in data_loaders.items():
    print(f"\n=== Training with {split*100:.1f}% training data and {(1-split)*100:.1f}% validation data ===")

    # Train for a fixed number of epochs (adjust as needed)
    for epoch in range(10):
        train_loss = train(model, train_loader, optimizer, criterion, device)
        # We still evaluate on validation set to track progress (optional printout)
        val_loss, val_acc1, val_acc2, val_acc3 = evaluate(model, val_loader, criterion, device)
        print(f"Epoch {epoch+1}: Training Loss = {train_loss:.4f}, Val Class Acc = {val_acc1:.4f}, "
              f"Val Superclass Acc = {val_acc2:.4f}, Val Group Acc = {val_acc3:.4f}")

    # Print the number of trainable and non-trainable parameters
    trainable_params, non_trainable_params = model.count_parameters()
    print(f"Trainable Parameters: {trainable_params}, Non-Trainable Parameters: {non_trainable_params}")

    # ===========================
    # Test Set Evaluation and Confusion Matrices for Each Classification Level
    # ===========================
    print(f"\nEvaluating on test set for split with {split*100:.1f}% training data...")
    model.eval()
    all_preds1, all_preds2, all_preds3 = [], [], []
    all_labels1, all_labels2, all_labels3 = [], [], []

    with torch.no_grad():
        for images, targets in test_loader:
            images, targets = images.to(device), targets.to(device)
            labels1, labels2, labels3 = get_labels(targets)
            labels1, labels2, labels3 = labels1.to(device), labels2.to(device), labels3.to(device)
            out1, out2, out3 = model(images)
            all_preds1.extend(out1.argmax(1).cpu().numpy())
            all_preds2.extend(out2.argmax(1).cpu().numpy())
            all_preds3.extend(out3.argmax(1).cpu().numpy())
            all_labels1.extend(labels1.cpu().numpy())
            all_labels2.extend(labels2.cpu().numpy())
            all_labels3.extend(labels3.cpu().numpy())

    # Plot confusion matrices for Class, Superclass, and Group for the current split
    plot_confusion_matrix(all_labels1, all_preds1, labels=[str(i) for i in range(100)],
                          title=f"Class Confusion Matrix ({split*100:.1f}% Train)")
    plot_confusion_matrix(all_labels2, all_preds2, labels=[str(i) for i in range(len(SUPERCLASS_TO_IDX))],
                          title=f"Superclass Confusion Matrix ({split*100:.1f}% Train)")
    plot_confusion_matrix(all_labels3, all_preds3, labels=[str(i) for i in range(len(GROUP_TO_IDX))],
                          title=f"Group Confusion Matrix ({split*100:.1f}% Train)")